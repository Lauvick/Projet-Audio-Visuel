"""
Script de d√©tection en batch - Analyse plusieurs vid√©os en parall√®le.
Utilise le multiprocessing pour acc√©l√©rer le traitement.
"""

import os
import sys
import io
import time
import argparse
from concurrent.futures import ProcessPoolExecutor, as_completed
from datetime import timedelta

# Forcer l'encodage UTF-8 pour la console Windows
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# Configuration FFmpeg AVANT import de pydub
CONDA_ENV = os.path.dirname(sys.executable)
FFMPEG_PATH = os.path.join(CONDA_ENV, "Library", "bin", "ffmpeg.exe")
FFPROBE_PATH = os.path.join(CONDA_ENV, "Library", "bin", "ffprobe.exe")

# Ajouter le dossier FFmpeg au PATH
if os.path.exists(os.path.dirname(FFMPEG_PATH)):
    os.environ["PATH"] = os.path.dirname(FFMPEG_PATH) + os.pathsep + os.environ.get("PATH", "")

# ============================================================
# CONFIGURATION
# ============================================================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
VIDEOS_FOLDER = os.path.join(BASE_DIR, "videos_theodore")
OUTPUT_FOLDER = os.path.join(BASE_DIR, "output_segments")
RESULTS_FOLDER = os.path.join(BASE_DIR, "batch_results")

# Nombre de processus parall√®les (ajuster selon votre CPU/RAM)
# 16 Go RAM ‚Üí 4 workers recommand√©
MAX_WORKERS = 4


def format_duration(seconds):
    """Formate une dur√©e en HH:MM:SS"""
    return str(timedelta(seconds=int(seconds)))


def analyze_single_video(video_path):
    """
    Analyse une seule vid√©o et retourne les r√©sultats.
    Cette fonction est ex√©cut√©e dans un processus s√©par√©.
    """
    import torch
    import soundfile as sf
    import numpy as np
    import pydub
    from pydub import AudioSegment
    from speechbrain.inference.classifiers import EncoderClassifier
    from scipy.spatial.distance import cosine
    import warnings
    
    # Supprimer les warnings pour un affichage plus propre
    warnings.filterwarnings('ignore')
    
    # Configurer pydub
    if os.path.exists(FFMPEG_PATH):
        pydub.AudioSegment.converter = FFMPEG_PATH
        pydub.AudioSegment.ffmpeg = FFMPEG_PATH
    if os.path.exists(FFPROBE_PATH):
        pydub.AudioSegment.ffprobe = FFPROBE_PATH
    
    video_name = os.path.basename(video_path)
    result = {
        'video': video_name,
        'status': 'error',
        'segments': [],
        'total_duration': 0,
        'theodore_duration': 0,
        'error': None
    }
    
    try:
        # Param√®tres
        VOICE_PRINT_FILE = os.path.join(BASE_DIR, "theodore_voice_print.pt")
        SEGMENT_DURATION_SEC = 3
        SIMILARITY_THRESHOLD = 0.95
        MIN_CONSECUTIVE_SEGMENTS = 1
        
        # Charger l'empreinte vocale
        if not os.path.exists(VOICE_PRINT_FILE):
            result['error'] = "Empreinte vocale non trouv√©e"
            return result
        
        reference_embedding = torch.load(VOICE_PRINT_FILE, weights_only=True)
        
        # Charger le mod√®le
        classifier = EncoderClassifier.from_hparams(
            source="speechbrain/spkrec-xvect-voxceleb",
            savedir=os.path.join(BASE_DIR, "models_cache"),
            run_opts={"device": "cpu"}
        )
        
        # Convertir la vid√©o en audio
        temp_wav = os.path.join(BASE_DIR, "processed_audio", f"temp_{os.getpid()}_{video_name}.wav")
        os.makedirs(os.path.dirname(temp_wav), exist_ok=True)
        
        audio = AudioSegment.from_file(video_path)
        audio = audio.set_channels(1).set_frame_rate(16000)
        audio.export(temp_wav, format="wav")
        
        # Charger l'audio
        signal, sr = sf.read(temp_wav)
        total_duration = len(signal) / sr
        result['total_duration'] = total_duration
        
        # Analyser par segments
        num_segments = int(total_duration / SEGMENT_DURATION_SEC)
        matches = []
        
        for i in range(num_segments):
            start_sample = int(i * SEGMENT_DURATION_SEC * sr)
            end_sample = int((i + 1) * SEGMENT_DURATION_SEC * sr)
            segment = signal[start_sample:end_sample]
            
            if len(segment) < sr:
                continue
            
            # Normaliser
            segment = segment.astype(np.float32)
            max_val = np.max(np.abs(segment))
            if max_val > 0:
                segment = segment / max_val
            
            # Calculer l'embedding
            segment_tensor = torch.tensor(segment).unsqueeze(0)
            embedding = classifier.encode_batch(segment_tensor)
            embedding = embedding.squeeze().detach().numpy()
            
            # Comparer
            similarity = 1 - cosine(reference_embedding.numpy().flatten(), embedding.flatten())
            
            if similarity >= SIMILARITY_THRESHOLD:
                matches.append({
                    'start': i * SEGMENT_DURATION_SEC,
                    'end': (i + 1) * SEGMENT_DURATION_SEC,
                    'similarity': similarity
                })
        
        # Consolider les segments cons√©cutifs
        if matches:
            consolidated = []
            current_start = matches[0]['start']
            current_end = matches[0]['end']
            
            for m in matches[1:]:
                if m['start'] <= current_end:
                    current_end = m['end']
                else:
                    consolidated.append({'start': current_start, 'end': current_end})
                    current_start = m['start']
                    current_end = m['end']
            
            consolidated.append({'start': current_start, 'end': current_end})
            result['segments'] = consolidated
            result['theodore_duration'] = sum(s['end'] - s['start'] for s in consolidated)
        
        result['status'] = 'success'
        
        # Nettoyer le fichier temporaire
        if os.path.exists(temp_wav):
            os.remove(temp_wav)
            
    except Exception as e:
        result['error'] = str(e)
    
    return result


def save_results(results, output_file):
    """Sauvegarde les r√©sultats dans un fichier."""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("R√âSULTATS DE L'ANALYSE EN BATCH\n")
        f.write("=" * 70 + "\n\n")
        
        total_videos = len(results)
        success_count = sum(1 for r in results if r['status'] == 'success')
        total_theodore_time = sum(r['theodore_duration'] for r in results)
        
        f.write(f"Vid√©os analys√©es: {total_videos}\n")
        f.write(f"Analyses r√©ussies: {success_count}\n")
        f.write(f"Temps total de Th√©odore: {format_duration(total_theodore_time)}\n\n")
        
        for r in results:
            f.write("-" * 50 + "\n")
            f.write(f"Vid√©o: {r['video']}\n")
            f.write(f"Statut: {r['status']}\n")
            
            if r['status'] == 'success':
                f.write(f"Dur√©e totale: {format_duration(r['total_duration'])}\n")
                f.write(f"Temps de Th√©odore: {format_duration(r['theodore_duration'])}\n")
                
                if r['segments']:
                    f.write(f"Segments ({len(r['segments'])}):\n")
                    for i, seg in enumerate(r['segments'], 1):
                        f.write(f"  {i}. {format_duration(seg['start'])} -> {format_duration(seg['end'])}\n")
                else:
                    f.write("Aucun segment d√©tect√©\n")
            else:
                f.write(f"Erreur: {r['error']}\n")
            f.write("\n")


def main():
    print("\n" + "=" * 70)
    print("üöÄ ANALYSE EN BATCH - D√âTECTION DU FR√àRE TH√âODORE")
    print("=" * 70)
    
    parser = argparse.ArgumentParser(description='Analyse plusieurs vid√©os en parall√®le')
    parser.add_argument('videos', nargs='*', help='Chemins des vid√©os √† analyser')
    parser.add_argument('--folder', '-f', help='Dossier contenant les vid√©os')
    parser.add_argument('--workers', '-w', type=int, default=MAX_WORKERS,
                        help=f'Nombre de processus parall√®les (d√©faut: {MAX_WORKERS})')
    args = parser.parse_args()
    
    # Collecter les vid√©os √† analyser
    video_files = []
    
    if args.videos:
        for v in args.videos:
            if os.path.isabs(v):
                video_files.append(v)
            else:
                # Chercher dans le dossier videos_theodore
                full_path = os.path.join(VIDEOS_FOLDER, v)
                if os.path.exists(full_path):
                    video_files.append(full_path)
                elif os.path.exists(v):
                    video_files.append(os.path.abspath(v))
    
    if args.folder:
        folder = args.folder if os.path.isabs(args.folder) else os.path.join(BASE_DIR, args.folder)
        if os.path.exists(folder):
            for f in os.listdir(folder):
                if f.endswith(('.mp4', '.mkv', '.avi', '.mov', '.webm')):
                    video_files.append(os.path.join(folder, f))
    
    # Si aucune vid√©o sp√©cifi√©e, utiliser toutes les vid√©os du dossier videos_theodore
    if not video_files and os.path.exists(VIDEOS_FOLDER):
        for f in os.listdir(VIDEOS_FOLDER):
            if f.endswith(('.mp4', '.mkv', '.avi', '.mov', '.webm')):
                video_files.append(os.path.join(VIDEOS_FOLDER, f))
    
    if not video_files:
        print("\n‚ùå Aucune vid√©o trouv√©e √† analyser.")
        print(f"   Placez vos vid√©os dans: {VIDEOS_FOLDER}")
        return
    
    # Supprimer les doublons
    video_files = list(set(video_files))
    
    print(f"\nüìÇ {len(video_files)} vid√©o(s) √† analyser:")
    for v in video_files:
        print(f"   ‚Ä¢ {os.path.basename(v)}")
    
    print(f"\n‚öôÔ∏è  Processus parall√®les: {args.workers}")
    print(f"üîÑ D√©marrage de l'analyse...\n")
    
    # Cr√©er le dossier de r√©sultats
    os.makedirs(RESULTS_FOLDER, exist_ok=True)
    
    # Lancer l'analyse en parall√®le
    start_time = time.time()
    results = []
    
    with ProcessPoolExecutor(max_workers=args.workers) as executor:
        # Soumettre toutes les t√¢ches
        future_to_video = {
            executor.submit(analyze_single_video, video): video 
            for video in video_files
        }
        
        # R√©cup√©rer les r√©sultats au fur et √† mesure
        completed = 0
        for future in as_completed(future_to_video):
            video = future_to_video[future]
            completed += 1
            
            try:
                result = future.result()
                results.append(result)
                
                status_icon = "‚úÖ" if result['status'] == 'success' else "‚ùå"
                if result['status'] == 'success':
                    print(f"   [{completed}/{len(video_files)}] {status_icon} {result['video']} "
                          f"- {len(result['segments'])} segment(s), "
                          f"{format_duration(result['theodore_duration'])} de Th√©odore")
                else:
                    print(f"   [{completed}/{len(video_files)}] {status_icon} {result['video']} "
                          f"- Erreur: {result['error']}")
                    
            except Exception as e:
                print(f"   [{completed}/{len(video_files)}] ‚ùå {os.path.basename(video)} - Exception: {e}")
                results.append({
                    'video': os.path.basename(video),
                    'status': 'error',
                    'segments': [],
                    'total_duration': 0,
                    'theodore_duration': 0,
                    'error': str(e)
                })
    
    elapsed_time = time.time() - start_time
    
    # Sauvegarder les r√©sultats
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    results_file = os.path.join(RESULTS_FOLDER, f"batch_results_{timestamp}.txt")
    save_results(results, results_file)
    
    # Afficher le r√©sum√©
    print("\n" + "=" * 70)
    print("üìä R√âSUM√â")
    print("=" * 70)
    
    success_count = sum(1 for r in results if r['status'] == 'success')
    total_theodore_time = sum(r['theodore_duration'] for r in results)
    total_video_time = sum(r['total_duration'] for r in results)
    
    print(f"\n‚úÖ Vid√©os analys√©es: {success_count}/{len(video_files)}")
    print(f"‚è±Ô∏è  Temps d'analyse: {format_duration(elapsed_time)}")
    print(f"üé¨ Dur√©e totale des vid√©os: {format_duration(total_video_time)}")
    print(f"üé§ Temps total de Th√©odore: {format_duration(total_theodore_time)}")
    print(f"\nüíæ R√©sultats sauvegard√©s: {results_file}")
    
    # Afficher les vid√©os avec le plus de contenu
    if results:
        sorted_results = sorted(
            [r for r in results if r['status'] == 'success'],
            key=lambda x: x['theodore_duration'],
            reverse=True
        )
        
        if sorted_results:
            print(f"\nüèÜ Top vid√©os (plus de contenu Th√©odore):")
            for i, r in enumerate(sorted_results[:5], 1):
                print(f"   {i}. {r['video']} - {format_duration(r['theodore_duration'])}")


if __name__ == "__main__":
    main()
