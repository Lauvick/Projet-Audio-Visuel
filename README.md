# ğŸ¬ Projet Audio-Visuel - FrÃ¨re ThÃ©odore

Application Windows pour la **dÃ©tection vocale automatique** et la **gÃ©nÃ©ration de shorts** avec sous-titres dynamiques mot par mot.

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Platform](https://img.shields.io/badge/Platform-Windows-lightgrey.svg)

## âœ¨ FonctionnalitÃ©s

- ğŸ¤ **DÃ©tection vocale** : Identifie automatiquement une voix spÃ©cifique dans une vidÃ©o (empreinte vocale)
- âœ‚ï¸ **GÃ©nÃ©ration de shorts** : Extrait les segments dÃ©tectÃ©s en clips courts
- ğŸ“ **Sous-titres dynamiques** : Affichage mot par mot synchronisÃ© avec la parole
- ğŸ¯ **Transcription prÃ©cise** : Utilise faster-whisper (large-v3) pour une transcription de qualitÃ©
- ğŸ® **DÃ©tection GPU automatique** : AccÃ©lÃ©ration CUDA si disponible
- ğŸ–¥ï¸ **Interface graphique moderne** : Application Windows avec thÃ¨me sombre/clair

## ğŸ“¸ AperÃ§u

L'application propose :
- SÃ©lection de vidÃ©os Ã  analyser
- Choix du modÃ¨le de transcription (Rapide vs PrÃ©cis)
- Pipeline complet : dÃ©tection â†’ extraction â†’ sous-titres
- Logs en temps rÃ©el avec progression

## ğŸš€ Installation

### PrÃ©requis

- **Python 3.10+** ([TÃ©lÃ©charger](https://www.python.org/downloads/))
- **FFmpeg** ([TÃ©lÃ©charger](https://ffmpeg.org/download.html)) - Doit Ãªtre dans le PATH
- **~5 GB d'espace disque** (pour les modÃ¨les IA)

### Ã‰tape 1 : Cloner le projet

```bash
git clone https://github.com/Lauvick/Projet-Audio-Visuel.git
cd Projet-Audio-Visuel
```

### Ã‰tape 2 : CrÃ©er un environnement virtuel

```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Linux/Mac
python3 -m venv .venv
source .venv/bin/activate
```

### Ã‰tape 3 : Installer les dÃ©pendances

```bash
pip install -r requirements.txt
pip install -r ai_agent/requirements_ai.txt
```

### Ã‰tape 4 : Premier lancement (tÃ©lÃ©chargement des modÃ¨les)

Au premier lancement, les modÃ¨les IA seront tÃ©lÃ©chargÃ©s automatiquement (~3 GB) :
- **SpeechBrain X-Vector** : Pour la dÃ©tection vocale
- **faster-whisper large-v3** : Pour la transcription

## ğŸ¯ Utilisation

### Lancer l'application graphique

```bash
python ai_agent/app_gui.py
```

Ou double-cliquez sur `Lancer_Application.bat`

### Interface

1. **SÃ©lectionnez une vidÃ©o** dans le menu dÃ©roulant
2. **Choisissez le modÃ¨le** :
   - âš¡ **Rapide** : ~3 min pour 10 min de vidÃ©o (CPU)
   - ğŸ¯ **PrÃ©cis** : ~17 min pour 10 min de vidÃ©o (CPU)
3. **Cliquez sur une action** :
   - ğŸš€ GÃ©nÃ©rer les Shorts : Pipeline complet
   - ğŸ“ Transcrire la vidÃ©o : Transcription seule (TXT + SRT)
   - ğŸ” Analyser : DÃ©tection vocale uniquement

### CrÃ©er une empreinte vocale personnalisÃ©e

Pour dÃ©tecter une voix spÃ©cifique, placez 2-3 fichiers audio (.wav, .mp3, .m4a) de cette personne dans `ai_agent/audio_theodore/` puis :

```bash
python ai_agent/create_voice_print.py
```

## ğŸ“ Structure du projet

```
Projet-Audio-Visuel/
â”œâ”€â”€ ai_agent/
â”‚   â”œâ”€â”€ app_gui.py              # ğŸ–¥ï¸ Application graphique principale
â”‚   â”œâ”€â”€ transcription_engine.py # ğŸ¤ Moteur faster-whisper
â”‚   â”œâ”€â”€ detect_theodore.py      # ğŸ” DÃ©tection vocale
â”‚   â”œâ”€â”€ generate_shorts.py      # âœ‚ï¸ GÃ©nÃ©ration de shorts
â”‚   â”œâ”€â”€ create_voice_print.py   # ğŸ¯ CrÃ©ation d'empreinte vocale
â”‚   â”œâ”€â”€ chatbot.py              # ğŸ¤– Interface chatbot (Ollama)
â”‚   â”œâ”€â”€ videos_theodore/        # ğŸ“¹ VidÃ©os Ã  analyser
â”‚   â”œâ”€â”€ shorts_theodore/        # ğŸ¬ Shorts gÃ©nÃ©rÃ©s
â”‚   â””â”€â”€ transcriptions/         # ğŸ“„ Fichiers de transcription
â”œâ”€â”€ requirements.txt            # ğŸ“¦ DÃ©pendances de base
â”œâ”€â”€ Lancer_Application.bat      # â–¶ï¸ Lanceur Windows
â””â”€â”€ README.md                   # ğŸ“– Documentation
```

## âš¡ Performance

| Mode | CPU (i7/Ryzen 7) | GPU NVIDIA |
|------|------------------|------------|
| **Rapide (small)** | ~0.3x temps rÃ©el | ~0.02x temps rÃ©el |
| **PrÃ©cis (large-v3)** | ~1.5x temps rÃ©el | ~0.1x temps rÃ©el |

*Exemple : VidÃ©o de 10 min â†’ 3 min (Rapide/CPU) ou 1 min (PrÃ©cis/GPU)*

## ğŸ”§ Configuration GPU (optionnel)

Si vous avez un GPU NVIDIA, installez CUDA pour des transcriptions 10x plus rapides :

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

L'application dÃ©tecte automatiquement le GPU au dÃ©marrage.

## ğŸ“ DÃ©pendances principales

- **faster-whisper** : Transcription audio ultra-rapide
- **speechbrain** : DÃ©tection et reconnaissance vocale
- **customtkinter** : Interface graphique moderne
- **FFmpeg** : Traitement vidÃ©o/audio

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  :
1. Fork le projet
2. CrÃ©er une branche (`git checkout -b feature/amelioration`)
3. Commit (`git commit -m 'Ajout fonctionnalitÃ©'`)
4. Push (`git push origin feature/amelioration`)
5. Ouvrir une Pull Request

## ğŸ“„ Licence

Ce projet est sous licence MIT - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ‘¤ Auteur

**Lauvick** - [GitHub](https://github.com/Lauvick)

---

â­ Si ce projet vous est utile, n'hÃ©sitez pas Ã  lui donner une Ã©toile !
